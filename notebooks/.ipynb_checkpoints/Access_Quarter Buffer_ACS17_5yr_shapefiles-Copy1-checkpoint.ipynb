{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "from earthpy.clip import clip_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bring in necessary geojson files and set your projection for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "wd = wd[:wd.find('notebooks')]\n",
    "\n",
    "#crs is set for Central Texas; https://epsg.io/6578; \n",
    "crs =  {'init' :'epsg:6578'}\n",
    "\n",
    "#parks = gpd.read_file(wd+\"data/coaparks/parkboundaries.geojson\")\n",
    "#parks = parks.to_crs(crs).explode().reset_index()\n",
    "\n",
    "quartbuff = gpd.read_file(wd+\"data/coaparks_buffer/quarterbuff.shp\")\n",
    "quartbuff.crs={'init' :'epsg:6578'}\n",
    "\n",
    "pop = gpd.read_file(wd+\"data/blockgroups_censusdata/popmerge.shp\")\n",
    "pop = pop.to_crs(crs).reset_index()\n",
    "\n",
    "race = gpd.read_file(wd+\"data/blockgroups_censusdata/racemerge.shp\")\n",
    "race = race.to_crs(crs).reset_index()\n",
    "\n",
    "income = gpd.read_file(wd+\"data/blockgroups_censusdata/incomemerge.shp\")\n",
    "income = income.to_crs(crs).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check your projections\n",
    "https://geopandas.org/projections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartbuff.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preview the files and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop['fullarea_pop'] = pop['geometry'].area\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race['fullarea_race'] = race['geometry'].area\n",
    "race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income['fullarea_income'] = income['geometry'].area\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartbuff['fullarea_buff'] = quartbuff['geometry'].area\n",
    "quartbuff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spatial analysis on the amount of people distributed within a census block group against the quarter mile park buffer area and the race census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rp_intersection = gpd.overlay(race, quartbuff, how='intersection') #https://geopandas.org/set_operations.html\n",
    "rp_intersection['area_intersec'] = rp_intersection['geometry'].area\n",
    "rp_intersection.to_file(wd+\"data/access/rp_intersec_quarterbuff_ACS17.shp\")\n",
    "rp_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_intersection.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_intersection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_intersection[['GEOID10','Total_POP','fullarea_race','LOCATION_N','fullarea_buff','area_intersec','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_clip=rp_intersection.copy().reset_index()\n",
    "\n",
    "for val in race_clip:\n",
    "\n",
    "    race_clip['weight'] = race_clip['area_intersec']/ race_clip['fullarea_race']\n",
    "    \n",
    "    race_clip['access_pop'] = race_clip['weight'] * race_clip['Total_POP']\n",
    "    race_clip['access_nonhis'] = race_clip['weight'] * race_clip['Not Hispan']\n",
    "    race_clip['access_white'] = race_clip['weight'] * race_clip['White; Not']\n",
    "    race_clip['access_his_lat'] = race_clip['weight'] * race_clip['Hispanic o']\n",
    "\n",
    "race_clip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_clip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_calc = race_clip[['LOCATION_N', 'access_pop', 'access_nonhis','access_white', 'access_his_lat','geometry']]\n",
    "access_data = race_calc.dissolve(by='LOCATION_N',as_index=False, aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The population served by parks is nomalized by dividing the population served by the area of the park for which they are being served "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_data['fullarea_park'] = access_data['geometry'].area\n",
    "\n",
    "access_data['Normalized_byArea'] = access_data['access_pop']/access_data['fullarea_park']\n",
    "access_data['Normalized_nonhis'] = access_data['access_nonhis']/access_data['fullarea_park']\n",
    "access_data['Normalized_white'] = access_data['access_white']/access_data['fullarea_park']\n",
    "access_data['Normalized_hislat'] = access_data['access_his_lat']/access_data['fullarea_park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "access_data.to_file(wd+\"data/access/access_data_race_ACS17.shp\")\n",
    "access_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dataframe is created with the 'acess_data' geoshapefile. This dataframe is cleaned up and the values are convereted into integers. Finally, we export the dataframe into a csv file and a shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(access_data)\n",
    "\n",
    "df['Park_Name']=df['LOCATION_N']\n",
    "df['Total_Pop_Served'] = df['access_pop'].astype(int)\n",
    "df['Normalized_byArea'] = df['Normalized_byArea'].astype(int)\n",
    "df['Non_Hispan'] = df['access_nonhis'].astype(int)\n",
    "df['Normalized_nonhis'] = df['Normalized_nonhis'].astype(int)\n",
    "df['White'] = df['access_white'].astype(int)\n",
    "df['Normalized_white'] = df['Normalized_white'].astype(int)\n",
    "df['Hispan_Latin'] = df['access_his_lat'].astype(int)\n",
    "df['Normalized_hislat'] = df['Normalized_hislat'].astype(int)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_race_final = df.copy().drop(columns=['LOCATION_N','access_pop','access_nonhis','access_white','access_his_lat'])\n",
    "access_race_final = gpd.GeoDataFrame(access_race_final, geometry='geometry')\n",
    "access_race_final.to_file(wd+\"data/access/access_race_final_ACS17.shp\")\n",
    "access_race_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_racetable = df.drop(columns=['LOCATION_N','access_pop','access_nonhis','access_white','access_his_lat', 'geometry'])\n",
    "access_racetable.to_csv(wd+\"data/access/access_table_race_ACS17.csv\")\n",
    "access_racetable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Race_access_stats = access_racetable.describe()\n",
    "Race_access_stats.to_csv(wd+\"data/access/access_stats_race_ACS17.csv\")\n",
    "Race_access_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access_racetable.hist('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spatial analysis on the amount of people distributed within a census block group against the quarter mile park buffer area and the income census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_intersection = gpd.overlay(income, quartbuff, how='intersection') #https://geopandas.org/set_operations.html\n",
    "ip_intersection['iarea_intersec'] = ip_intersection['geometry'].area\n",
    "ip_intersection.to_file(wd+\"data/access/ip_intersec_quarterbuff_ACS17.shp\")\n",
    "ip_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_intersection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ip_intersection[['GEOID10','Total_Pop','fullarea_income','LOCATION_N','fullarea_buff','iarea_intersec','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_intersection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_clip=ip_intersection.copy().reset_index()\n",
    "\n",
    "for val in income_clip:\n",
    "\n",
    "    income_clip['weight'] = income_clip['iarea_intersec']/ income_clip['fullarea_income']\n",
    "    \n",
    "    income_clip['access_by_income_TotalPop'] = income_clip['weight'] * income_clip['Total_Pop']\n",
    "    \n",
    "    income_clip['Less than $25,000'] = (income_clip['weight'] * income_clip['Less than'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$10,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$15,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$20,000 to'])\n",
    "    \n",
    "    income_clip['$25,000 to $49,999'] = (income_clip['weight'] * income_clip['$25,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$30,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$35,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$40,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$45,000 to'])\\\n",
    "    \n",
    "    income_clip['$50,000 to $74,999'] = (income_clip['weight'] * income_clip['$50,000 to'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$60,000 to'])\\\n",
    "    \n",
    "    income_clip['$75,000 to $99,999'] = (income_clip['weight'] * income_clip['$75,000 to'])\n",
    "    \n",
    "    income_clip['$100,000 to $149,999'] = (income_clip['weight'] * income_clip['$100,000 t'])\\\n",
    "                                            +(income_clip['weight'] * income_clip['$125,000 t'])\\\n",
    "    \n",
    "    income_clip['$150,000 or more'] = (income_clip['weight'] * income_clip['$150,000 t'])\\\n",
    "                                        +(income_clip['weight'] * income_clip['$200,000 o'])\\\n",
    "    \n",
    "income_clip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_clip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_calc = income_clip[['LOCATION_N', 'access_by_income_TotalPop', 'Less than $25,000','$25,000 to $49,999',\\\n",
    "                           '$50,000 to $74,999','$75,000 to $99,999','$100,000 to $149,999','$150,000 or more','geometry']]\n",
    "\n",
    "income_access_data = income_calc.dissolve(by='LOCATION_N',as_index=False, aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The population served by parks is nomalized by dividing the population served by the area of the park for which they are being served "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_access_data['fullarea_p'] = income_access_data['geometry'].area\n",
    "\n",
    "income_access_data['Normalized_byArea'] = income_access_data['access_by_income_TotalPop']/income_access_data['fullarea_p']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_access_data.to_file(wd+\"data/access/access_data_income_ACS17.shp\")\n",
    "income_access_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dataframe is created with the 'acess_data' geoshapefile. This dataframe is cleaned up and the values are convereted into integers. Finally, we export the dataframe into a csv file and a shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(income_access_data)\n",
    "df['Park_Name']=df['LOCATION_N']\n",
    "\n",
    "df['Total Pop Served'] = df['access_by_income_TotalPop'].astype(int)\n",
    "df['Less than $25,000'] = df['Less than $25,000'].astype(int)\n",
    "df['$25,000 to $49,999'] = df['$25,000 to $49,999'].astype(int)\n",
    "df['$50,000 to $74,999'] = df['$50,000 to $74,999'].astype(int)\n",
    "df['$75,000 to $99,999'] = df['$75,000 to $99,999'].astype(int)\n",
    "df['$100,000 to $149,999'] = df['$100,000 to $149,999'].astype(int)\n",
    "df['$150,000 or more'] = df['$150,000 or more'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_income_final = df.copy().drop(columns=['access_by_income_TotalPop'])\n",
    "access_income_final = gpd.GeoDataFrame(access_income_final, geometry='geometry')\n",
    "access_income_final.to_file(wd+\"data/access/access_income_final_ACS17.shp\")\n",
    "access_income_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_incometable = df.drop(columns=['access_by_income_TotalPop','geometry'])\n",
    "access_incometable.to_csv(wd+\"data/access/access_table_income_ACS17.csv\")\n",
    "access_incometable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_income_stats = access_incometable.describe()\n",
    "access_income_stats.to_csv(wd+\"data/access/access_stats_income_ACS17.csv\")\n",
    "access_income_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following are cells of unused code or code that does not work in its current form"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parkspop = df.copy()\n",
    "quartbuff = gpd.read_file(wd+\"data/coaparks_buffer/quarterbuffgj.geojson\")\n",
    "qbuff = quartbuff.copy()\n",
    "parksnocem= qbuff.loc[~qbuff['LOCATION_N'].str.contains('Cemetery')].reset_index()\n",
    "parks_pop = parksnocem.merge(parkspop, left_on='LOCATION_N', right_on='Park_Name', suffixes=('_parksnocem', '_parkspop'))\n",
    "parks_pop.to_file(wd+\"data/access/parks_pop_quarterbuff_ACS17.shp\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = {'Park_Name':[],\n",
    "       'Calc_Pop':[]}\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "names = quartbuff['LOCATION_N'].unique()\n",
    "for i, dfrow in parks.iterrows():\n",
    "     name = dfrow['LOCATION_N']\n",
    "\n",
    "for i,name in enumerate(names):\n",
    "    park = quartbuff.loc[quartbuff['LOCATION_N'] == name]\n",
    "    park['geometry'] = park['geometry'].buffer(0) #This is the buffer\n",
    "#     print(i, name)\n",
    "    \n",
    "    is_in_park = False\n",
    "    for j, dfrow in pop.iterrows(): # iterate over pop shapes\n",
    "#         print(dfrow['geometry'].is_valid)\n",
    "        for n, dfrow2 in park.iterrows(): # iterate over buffered park shape\n",
    "            # check if any pop shps fall within the buffered park shapes\n",
    "            if Polygon(dfrow['geometry']).intersects(Polygon(dfrow2['geometry'])):\n",
    "                is_in_park = True\n",
    "                break\n",
    "    if is_in_park:\n",
    "        pop_valid = pop.copy()\n",
    "        pop_valid['geometry'] = pop_valid['geometry'].buffer(0) # fix invalid polygons by buffering them by zero distances\n",
    "        # definetly a hack and should be looked into.\n",
    "        pop_clip = clip_shp(pop_valid,park)\n",
    "\n",
    "        pop_clip['new_area'] = pop_clip['geometry'].area\n",
    "        pop_clip['weight'] = pop_clip['new_area']/ pop_clip['full_area']\n",
    "        pop_clip['new_pop'] = pop_clip['weight'] * pop_clip['Estimate;']\n",
    "\n",
    "        data['Park_Name'].append(name)\n",
    "        data['Calc_Pop'].append(pop_clip['new_pop'].sum())\n",
    "    else: # if no pop blocks are within the park then return 0\n",
    "        data['Park_Name'].append(name)\n",
    "        data['Calc_Pop'].append(0)\n",
    "\n",
    "# print(park.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "data = {'LOCATION_N':[],'access_pop':[],'access_nonhis':[],'access_white':[],'access_his_lat':[]}\n",
    "\n",
    "#data['Park_Name'].append(name)\n",
    "data['access_pop'].append(access_data['access_pop'])\n",
    "data['access_nonhis'].append(access_data['access_nonhis'])\n",
    "data['White'].append(access_data['access_white'])\n",
    "data['Hispan_Latin'].append(access_data['access_his_lat'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "base = rp_intersection.plot(ax=ax, color=\"black\", alpha=0.2)\n",
    "layer = rp_intersection[\"geometry\"].plot(ax=base, color='black', edgecolor = 'black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
